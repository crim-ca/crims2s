{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parametric Distribution\n",
    "\n",
    "Allow the use of any parametric distribution instead of only being able to have normal distributions when making a forecast probabilistic.\n",
    "The difficult part is fitting more exotic distributions such as a gamma for every lat lon in the xdataset.\n",
    "\n",
    "There seems to be a good reference in xclim: https://github.com/Ouranosinc/xclim/blob/f9d53c4cccb51174495860905c766f184796fc51/xclim/indices/stats.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.array as da\n",
    "import dask.distributed\n",
    "import dask_jobqueue\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import scipy.stats\n",
    "import xarray as xr\n",
    "import xskillscore as xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crims2s.util import fix_dataset_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_TRAIN = '***BASEDIR***training-input/0.3.0/netcdf'\n",
    "OBSERVATIONS = '***BASEDIR***training-output-reference/'\n",
    "BENCHNMARK = '***BASEDIR***training-output-benchmark/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boost dask cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = dask_jobqueue.SLURMCluster(\n",
    "    env_extra=['source ***HOME***.bash_profile','conda activate s2s'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(jobs=3)  # Scale to two working nodes as configured.\n",
    "client = dask.distributed.Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ECMWF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CENTER = 'ecmwf'\n",
    "FIELD = 't2m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = pathlib.Path(INPUT_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files = sorted([f for f in input_path.iterdir() if CENTER in f.stem and FIELD in f.stem])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecmwf = xr.open_mfdataset(input_files, preprocess=fix_dataset_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecmwf_w34 = ecmwf.sel(lead_time=slice('14D', '27D'))\n",
    "ecmwf_w34_train = ecmwf_w34.sel(forecast_year=slice(None, 2018))\n",
    "ecmwf_w34_val = ecmwf_w34.sel(forecast_year=slice(2019, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecmwf_w34_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_path = pathlib.Path(OBSERVATIONS)\n",
    "obs_files = [f for f in obs_path.iterdir() if 't2m' in f.stem]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = xr.open_mfdataset(obs_files, preprocess=fix_dataset_dims).isel(lead_time=slice(1, None))\n",
    "obs_w34 = obs.sel(lead_time=slice('14D', '27D'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_w34_train = obs_w34.sel(forecast_year=slice(None, 2018))\n",
    "obs_w34_val = obs_w34.sel(forecast_year=slice(2019, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_w34_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-parametric\n",
    "\n",
    "The first thing I want to try is a totally non parametric version, I think it will be easiest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_train_thresholds = obs_w34_train.quantile([0.33, 0.66], dim=['lead_time', 'forecast_year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_train_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecmwf_w34_val.dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_lead_time = ecmwf_w34_val.dims['lead_time']\n",
    "n_lead_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "below = (obs_w34_val < obs_train_thresholds.isel(quantile=0)).sum(dim=['lead_time']).drop_vars('quantile') / n_lead_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whithin = ((obs_w34_val < obs_train_thresholds.isel(quantile=1)) & (obs_w34_val >= obs_train_thresholds.isel(quantile=0))).sum(dim='lead_time') / n_lead_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whithin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "above = (obs_w34_val >= obs_train_thresholds.isel(quantile=1)).sum(dim=['lead_time']).drop_vars('quantile') / n_lead_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whithin.isel(forecast_dayofyear=0).t2m.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(whithin + above + below).t2m.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "below.t2m.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "above.t2m.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = xr.concat([below, whithin, above], 'category').assign_coords(category=['below normal', 'near normal', 'above normal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "land_mask = ~obs_w34_val.isel(forecast_dayofyear=0, lead_time=0, forecast_year=0).t2m.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "land_mask.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_forecast = xr.where(land_mask, forecast, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_forecast.isel(forecast_dayofyear=0, category=0).t2m.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast.isel(category=2, forecast_dayofyear=0).t2m.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast.sum(dim='category').isel(forecast_dayofyear=0).t2m.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_probabilistic_non_parametric(model, thresholds, dim=None):\n",
    "    if dim is None:\n",
    "        dim = model.dims.keys()\n",
    "    elif isinstance(dim, str):\n",
    "        dim = [dim]\n",
    "    \n",
    "    dims_sizes = [model.dims[d] for d in dim]\n",
    "    sample_size = np.prod(dims_sizes)\n",
    "    \n",
    "    below = (model < thresholds.isel(quantile=0)).sum(dim=dim).drop_vars('quantile') / sample_size\n",
    "    whithin = ((model < thresholds.isel(quantile=1)) & (model >= thresholds.isel(quantile=0))).sum(dim=dim) / sample_size\n",
    "    above = (model >= thresholds.isel(quantile=1)).sum(dim=dim).drop_vars('quantile') / sample_size\n",
    "    \n",
    "    return xr.concat([below, whithin, above], 'category').assign_coords(category=['below normal', 'near normal', 'above normal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = make_probabilistic_non_parametric(obs_w34_val, obs_train_thresholds, dim='lead_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.isel(forecast_dayofyear=0, category=2).t2m.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.isel(forecast_dayofyear=0).sum(dim='category').t2m.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal parametric ditribution\n",
    "\n",
    "This is a little bit of an easier case because we can estimate the distribution parameters using mean and std."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arbitrary parametric distritbution\n",
    "\n",
    "This is the most complicated case because we have to use scipy's distribution parameter function on some of the dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "S2S Challenge",
   "language": "python",
   "name": "s2s"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
