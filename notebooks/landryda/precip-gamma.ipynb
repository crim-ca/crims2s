{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.distributions\n",
    "import scipy.stats as stats\n",
    "import xarray as xr\n",
    "\n",
    "from crims2s.dataset import S2SDataset, TransformedDataset\n",
    "from crims2s.transform import AddBiweeklyDimTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = '***BASEDIR***/mlready/2021-08-21-test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = S2SDataset(DATASET, include_features=False, name_filter=lambda x: x.endswith('0102.nc'))\n",
    "dataset = TransformedDataset(dataset, AddBiweeklyDimTransform())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = dataset[0]['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_wrapper(*args, **kwargs):\n",
    "    ret = stats.gamma.fit(*args, **kwargs)\n",
    "    ret_np = np.array(ret)\n",
    "    return ret_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scipy_fit = xr.apply_ufunc(fit_wrapper, model.tp.isel(lead_time=-1, latitude=slice(0,10), longitude=slice(0,10)), input_core_dims=[['realization']], output_core_dims=[['parameter']], vectorize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit gamma using pytorch\n",
    "\n",
    "The fitting is too slow using scipy stats. We'll have to make that logic using pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REG = 1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_total = model.tp.isel(lead_time=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial estimate using the method of moments.\n",
    "\n",
    "a_hat_xarray = weekly_total.mean(dim='realization') ** 2 / (weekly_total.var(dim='realization') + REG)\n",
    "b_hat_xarray = (weekly_total.mean(dim='realization') + REG) / (weekly_total.var(dim='realization') + REG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(a_hat_xarray / b_hat_xarray**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_tp = a_hat_xarray / b_hat_xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_tp.isel(biweekly_forecast=1).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_hat =torch.tensor(a_hat_xarray.data, requires_grad=True)\n",
    "b_hat = torch.tensor(b_hat_xarray.data, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_total_torch = torch.clamp(torch.from_numpy(weekly_total.transpose('realization', 'biweekly_forecast', 'latitude', 'longitude').data), min=REG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_total_torch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam([a_hat, b_hat], lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_total_torch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_lls = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(50):\n",
    "    estimated_gamma = torch.distributions.Gamma(torch.clamp(a_hat, min=REG) , torch.clamp(b_hat, min=REG))\n",
    "\n",
    "    mean_log_likelihood = estimated_gamma.log_prob(weekly_total_torch).mean()\n",
    "\n",
    "    mean_lls.append(-mean_log_likelihood.detach().item())\n",
    "\n",
    "    loss = -mean_log_likelihood\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mean_lls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow((a_hat.detach() / b_hat.detach())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_hat.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_hat.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(a_hat / b_hat).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_gamma_xarray(array: xr.DataArray, dim=None, regularization=1e-9, **kwargs):\n",
    "    \"\"\"\"\"\"\n",
    "    # Use method of moments for initial estimate.\n",
    "    a_hat_xarray = array.mean(dim=dim) ** 2 / (array.var(dim=dim) + regularization)\n",
    "    b_hat_xarray = (array.mean(dim=dim) + regularization) / (array.var(dim=dim) + regularization)\n",
    "    \n",
    "    transposed = array.transpose(dim, ...)\n",
    "    \n",
    "    alpha, beta = fit_gamma_pytorch(transposed.data, a_hat_xarray.data, b_hat_xarray.data, regularization=regularization, **kwargs)\n",
    "    \n",
    "    alpha_xarray = xr.zeros_like(a_hat_xarray).rename(f'{a_hat_xarray.name}_alpha')\n",
    "    beta_xarray = xr.zeros_like(b_hat_xarray).rename(f'{a_hat_xarray.name}_beta')\n",
    "    \n",
    "    alpha_xarray.data = alpha.numpy()\n",
    "    beta_xarray.data = beta.numpy()\n",
    "    \n",
    "    return xr.merge([alpha_xarray, beta_xarray])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_gamma_pytorch(data, a_hat, b_hat, regularization=1e-9, max_epochs=500, lr=1e-2, tol=1e-5, patience=5, return_losses=False):\n",
    "    n_iter_waited = 0\n",
    "    \n",
    "    alpha = torch.tensor(a_hat, requires_grad=True)\n",
    "    beta = torch.tensor(b_hat, requires_grad=True)\n",
    "    data = torch.tensor(data)\n",
    "    \n",
    "    optimizer = torch.optim.Adam([alpha, beta], lr=lr)\n",
    "    log_likelihoods = []\n",
    "    for epoch in range(max_epochs):\n",
    "        clamped_alpha = torch.clamp(alpha, min=regularization)\n",
    "        clamped_beta = torch.clamp(beta, min=regularization)\n",
    "        \n",
    "        estimated_gamma = torch.distributions.Gamma(clamped_alpha , clamped_beta)\n",
    "\n",
    "        loss = -estimated_gamma.log_prob(data).mean()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if len(log_likelihoods) > 0:\n",
    "            percent_improvement = log_likelihoods[-1] / loss - 1.0\n",
    "            best_loss = np.array(log_likelihoods).min()\n",
    "            if np.abs(best_loss - loss.detach()) < tol:\n",
    "                n_iter_waited += 1\n",
    "                \n",
    "                if n_iter_waited >= patience:\n",
    "                    break\n",
    "        \n",
    "        log_likelihoods.append(loss.detach().item())\n",
    "            \n",
    "    alpha, beta = torch.clamp(alpha, min=regularization).detach(), torch.clamp(beta, min=regularization).detach()\n",
    "\n",
    "    if return_losses:\n",
    "        return alpha, beta, log_likelihoods\n",
    "    else:\n",
    "        return alpha, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_params = fit_gamma_xarray(model.tp.isel(lead_time=-1).clip(min=1e-9), dim='realization', tol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_params.tp_beta.isel(biweekly_forecast=1).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "S2S Challenge",
   "language": "python",
   "name": "s2s"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
