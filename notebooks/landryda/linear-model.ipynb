{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Model\n",
    "\n",
    "Train a linear model for a single dayofyear using one of the ml datasets we made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.distributions\n",
    "import xarray as xr\n",
    "\n",
    "from crims2s.dataset import S2SDataset, TransformedDataset\n",
    "from crims2s.transform import CompositeTransform, add_biweekly_dim_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = '***BASEDIR***/mlready/2021-08-07-test/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make transform to interface dataset w/ linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_estimator(dataset, dim=None):\n",
    "    dataset_mean = dataset.mean(dim=dim)\n",
    "    \n",
    "    if dim is None:\n",
    "        dim_sizes = [dataset.sizes[x] for x in dataset_mean.dims]\n",
    "    elif isinstance(dim, str):\n",
    "        dim_sizes = dataset.sizes[dim]\n",
    "    else:\n",
    "        dim_sizes = [dataset.sizes[x] for x in dim]\n",
    "    \n",
    "    n = np.prod(dim_sizes)\n",
    "    \n",
    "    return xr.ufuncs.sqrt(xr.ufuncs.square(dataset - dataset_mean).sum(dim=dim) / (n - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_to_distribution(model):   \n",
    "    model_tp_mean = model.tp.isel(lead_time=-1).mean(dim='realization').rename('tp_mean')\n",
    "    model_tp_std = std_estimator(model.tp.isel(lead_time=-1), dim='realization').rename('tp_std')\n",
    "    \n",
    "    model_t2m_mean = model.t2m.mean(dim=['lead_time', 'realization']).rename('t2m_mean')\n",
    "    model_t2m_std = std_estimator(model.t2m, dim=['lead_time', 'realization']).rename('t2m_std')\n",
    "    \n",
    "    return xr.merge([\n",
    "        model_tp_mean, model_tp_std, model_t2m_mean, model_t2m_std\n",
    "    ]).drop('lead_time').rename(biweekly_forecast='lead_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obs_to_biweekly(obs):\n",
    "    aggregate_obs_tp = obs.pr.sum(dim='lead_time', min_count=2).rename('tp')\n",
    "    aggregate_obs_t2m = obs.t2m.mean(dim='lead_time')\n",
    "    return xr.merge([aggregate_obs_tp, aggregate_obs_t2m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_model_adapter(example):\n",
    "    model = model_to_distribution(example['model'])\n",
    "    obs = obs_to_biweekly(example['obs'])\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'obs': obs\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_pytorch(example):\n",
    "    model = example['model']\n",
    "    obs = example['obs']\n",
    "    \n",
    "    return {\n",
    "        'model_tp_mu': torch.from_numpy(model.tp_mean.data),\n",
    "        'model_tp_sigma': torch.from_numpy(model.tp_std.data),\n",
    "        'model_t2m_mu': torch.from_numpy(model.t2m_mean.data),\n",
    "        'model_t2m_sigma': torch.from_numpy(model.t2m_std.data),\n",
    "        'obs_t2m': torch.from_numpy(obs.t2m.data),\n",
    "        'obs_tp': torch.from_numpy(obs.tp.data),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = CompositeTransform([add_biweekly_dim_transform, linear_model_adapter, to_pytorch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TransformedDataset(S2SDataset(DATASET, filter_str='0102.nc', include_features=False), transform)\n",
    "val_dataset = TransformedDataset(S2SDataset(DATASET, filter_str='0102.nc', include_features=False), transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(train_dataset, num_workers=2, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_mu_intercept = torch.zeros(3, 121, 240, requires_grad=True)\n",
    "tp_mu_weights = torch.zeros(3, 121, 240, requires_grad=True)\n",
    "tp_sigma_intercept = torch.ones(3, 121, 240, requires_grad=True)\n",
    "tp_sigma_weights = torch.zeros(3, 121, 240, requires_grad=True)\n",
    "\n",
    "t2m_mu_intercept = torch.zeros(3, 121, 240, requires_grad=True)\n",
    "t2m_mu_weights = torch.zeros(3, 121, 240, requires_grad=True)\n",
    "t2m_sigma_intercept = torch.full((3, 121, 240), 2.0, requires_grad=True)\n",
    "t2m_sigma_weights = torch.zeros(3, 121, 240, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(params=[tp_mu_intercept, tp_mu_weights, tp_sigma_intercept, tp_sigma_weights, t2m_mu_intercept, t2m_mu_weights, t2m_sigma_intercept, t2m_sigma_weights], lr=5e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(5):\n",
    "    for example in dataloader:\n",
    "        model_tp_mu, model_tp_sigma = example['model_tp_mu'], example['model_tp_sigma']\n",
    "        tp_mu = tp_mu_intercept + tp_mu_weights * model_tp_mu + model_tp_mu\n",
    "        tp_sigma = tp_sigma_intercept + tp_sigma_weights * model_tp_sigma + model_tp_sigma\n",
    "        tp_sigma = torch.clip(tp_sigma, min=1e-6)\n",
    "\n",
    "        model_t2m_mu, model_t2m_sigma = example['model_t2m_mu'], example['model_t2m_sigma']\n",
    "        t2m_mu = t2m_mu_intercept + t2m_mu_weights * model_t2m_mu + model_t2m_mu\n",
    "        t2m_sigma = t2m_sigma_intercept + t2m_sigma_weights * model_t2m_sigma + model_t2m_sigma\n",
    "        t2m_sigma = torch.clip(t2m_sigma, min=1e-6)\n",
    "        \n",
    "\n",
    "        tp_dist = torch.distributions.Normal(loc=tp_mu, scale=tp_sigma)\n",
    "        t2m_dist = torch.distributions.Normal(loc=t2m_mu, scale=t2m_sigma)\n",
    "\n",
    "        tp_obs = example['obs_t2m']\n",
    "        tp_nan_mask = tp_obs.isnan()\n",
    "        tp_obs[tp_nan_mask] = 0.0\n",
    "        tp_log_likelihood = tp_dist.log_prob(tp_obs)\n",
    "        tp_log_likelihood[tp_nan_mask] = 0.0\n",
    "\n",
    "        t2m_obs = example['obs_t2m']\n",
    "        t2m_nan_mask = tp_obs.isnan()\n",
    "        t2m_obs[t2m_nan_mask] = 0.0\n",
    "        t2m_log_likelihood = t2m_dist.log_prob(tp_obs)\n",
    "        t2m_log_likelihood[t2m_nan_mask] = 0.0\n",
    "\n",
    "        rain_loss = -tp_log_likelihood.mean()\n",
    "        temperature_loss =  -t2m_log_likelihood.mean()\n",
    "        loss = rain_loss + temperature_loss\n",
    "\n",
    "        print(f'T2M: {temperature_loss}, TP: {rain_loss}, TOTAL: {loss}')\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2m_sigma_intercept.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_sigma_intercept[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=t2m_mu_weights[2].detach().numpy().flatten(), bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2m_mu_weights[2].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2m_mu_weights.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "S2S Challenge",
   "language": "python",
   "name": "s2s"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
