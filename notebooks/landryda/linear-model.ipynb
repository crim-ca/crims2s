{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Model\n",
    "\n",
    "Train a linear model for a single dayofyear using one of the ml datasets we made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.distributions\n",
    "import torch.nn as nn\n",
    "import xarray as xr\n",
    "\n",
    "from crims2s.dataset import S2SDataset, TransformedDataset\n",
    "from crims2s.transform import CompositeTransform, add_biweekly_dim_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = '***BASEDIR***/mlready/2021-08-08-test/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make transform to interface dataset w/ linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_estimator(dataset, dim=None):\n",
    "    dataset_mean = dataset.mean(dim=dim)\n",
    "    \n",
    "    if dim is None:\n",
    "        dim_sizes = [dataset.sizes[x] for x in dataset_mean.dims]\n",
    "    elif isinstance(dim, str):\n",
    "        dim_sizes = dataset.sizes[dim]\n",
    "    else:\n",
    "        dim_sizes = [dataset.sizes[x] for x in dim]\n",
    "    \n",
    "    n = np.prod(dim_sizes)\n",
    "    \n",
    "    return xr.ufuncs.sqrt(xr.ufuncs.square(dataset - dataset_mean).sum(dim=dim) / (n - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_to_distribution(model):   \n",
    "    model_tp_mean = model.tp.isel(lead_time=-1).mean(dim='realization').rename('tp_mean')\n",
    "    model_tp_std = std_estimator(model.tp.isel(lead_time=-1), dim='realization').rename('tp_std')\n",
    "    \n",
    "    model_t2m_mean = model.t2m.mean(dim=['lead_time', 'realization']).rename('t2m_mean')\n",
    "    model_t2m_std = std_estimator(model.t2m, dim=['lead_time', 'realization']).rename('t2m_std')\n",
    "    \n",
    "    return xr.merge([\n",
    "        model_tp_mean, model_tp_std, model_t2m_mean, model_t2m_std\n",
    "    ]).drop('lead_time').rename(biweekly_forecast='lead_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obs_to_biweekly(obs):\n",
    "    aggregate_obs_tp = obs.pr.sum(dim='lead_time', min_count=2).rename('tp')\n",
    "    aggregate_obs_t2m = obs.t2m.mean(dim='lead_time')\n",
    "    return xr.merge([aggregate_obs_tp, aggregate_obs_t2m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_model_adapter(example):\n",
    "    model = model_to_distribution(example['model'])\n",
    "    obs = obs_to_biweekly(example['obs'])\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'obs': obs\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_pytorch(example):\n",
    "    model = example['model']\n",
    "    obs = example['obs']\n",
    "    \n",
    "    return {\n",
    "        'model_tp_mu': torch.from_numpy(model.tp_mean.data),\n",
    "        'model_tp_sigma': torch.from_numpy(model.tp_std.data),\n",
    "        'model_t2m_mu': torch.from_numpy(model.t2m_mean.data),\n",
    "        'model_t2m_sigma': torch.from_numpy(model.t2m_std.data),\n",
    "        'obs_t2m': torch.from_numpy(obs.t2m.data),\n",
    "        'obs_tp': torch.from_numpy(obs.tp.data),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = CompositeTransform([add_biweekly_dim_transform, linear_model_adapter, to_pytorch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TransformedDataset(S2SDataset(DATASET, filter_str='0312.nc', include_features=False, years=list(range(2000,2017))), transform)\n",
    "val_dataset = TransformedDataset(S2SDataset(DATASET, filter_str='0312.nc', include_features=False, years=list(range(2017,2020))), transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, num_workers=4, batch_size=1)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, num_workers=1, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel(nn.Module):\n",
    "    def __init__(self, *shape, fill_weights=0.0, fill_intercept=0.0):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.weights = nn.Parameter(torch.full(shape, fill_weights))\n",
    "        self.intercept = nn.Parameter(torch.full(shape, fill_intercept))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.intercept + self.weights * x + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TempPrecipEMOS(nn.Module):\n",
    "    def __init__(self, biweekly=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        shape = (3, 121, 240) if biweekly else (121, 240)\n",
    "        \n",
    "        self.tp_mu_model = LinearModel(*shape)\n",
    "        self.tp_sigma_model = LinearModel(*shape, fill_intercept=1.0)\n",
    "        \n",
    "        self.t2m_mu_model = LinearModel(*shape)\n",
    "        self.t2m_sigma_model = LinearModel(*shape, fill_intercept=1.0)\n",
    "        \n",
    "    def forward(self, forecast_t2m_mu, forecast_t2m_sigma, forecast_tp_mu, forecast_tp_sigma):\n",
    "        tp_mu = self.tp_mu_model(forecast_tp_mu)\n",
    "        tp_sigma = self.tp_sigma_model(forecast_tp_sigma)\n",
    "        tp_sigma = torch.clip(tp_sigma, min=1e-6)\n",
    "\n",
    "        t2m_mu = self.t2m_mu_model(forecast_t2m_mu)\n",
    "        t2m_sigma = self.t2m_sigma_model(forecast_t2m_sigma)\n",
    "        t2m_sigma = torch.clip(t2m_sigma, min=1e-6)\n",
    "        \n",
    "        tp_dist = torch.distributions.Normal(loc=tp_mu, scale=tp_sigma)\n",
    "        t2m_dist = torch.distributions.Normal(loc=t2m_mu, scale=t2m_sigma)\n",
    "        \n",
    "        return t2m_dist, tp_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TempPrecipEMOS(biweekly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(6):\n",
    "    train_losses = []\n",
    "    train_temperature_losses = []\n",
    "    train_rain_losses = []\n",
    "    \n",
    "    model.train()\n",
    "    for example in train_dataloader:\n",
    "        model_tp_mu, model_tp_sigma = example['model_tp_mu'], example['model_tp_sigma']\n",
    "        #model_tp_mu, model_tp_sigma = model_tp_mu.cuda(), model_tp_sigma.cuda()\n",
    "        \n",
    "        model_t2m_mu, model_t2m_sigma = example['model_t2m_mu'], example['model_t2m_sigma']\n",
    "        #model_t2m_mu, model_t2m_sigma = model_t2m_mu.cuda(), model_t2m_sigma.cuda()\n",
    "        \n",
    "        t2m_dist, tp_dist = model.forward(model_t2m_mu, model_t2m_sigma, model_tp_mu, model_tp_sigma)\n",
    "\n",
    "        tp_obs = example['obs_tp']\n",
    "        tp_nan_mask = tp_obs.isnan()\n",
    "        tp_obs[tp_nan_mask] = 0.0\n",
    "        tp_log_likelihood = tp_dist.log_prob(tp_obs)\n",
    "        tp_log_likelihood[tp_nan_mask] = 0.0\n",
    "\n",
    "        t2m_obs = example['obs_t2m']\n",
    "        t2m_nan_mask = t2m_obs.isnan()\n",
    "        t2m_obs[t2m_nan_mask] = 0.0\n",
    "        t2m_log_likelihood = t2m_dist.log_prob(t2m_obs)\n",
    "        t2m_log_likelihood[t2m_nan_mask] = 0.0\n",
    "\n",
    "        rain_loss = -tp_log_likelihood.mean()\n",
    "        temperature_loss =  -t2m_log_likelihood.mean()\n",
    "        loss = rain_loss + temperature_loss\n",
    "        \n",
    "        loss.backward()\n",
    "                \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        train_losses.append(float(loss.detach()))\n",
    "        train_temperature_losses.append(float(temperature_loss.detach()))\n",
    "        train_rain_losses.append(float(rain_loss.detach()))\n",
    "\n",
    "    train_mean_loss = np.array(train_losses).mean()\n",
    "    train_mean_rain_loss = np.array(train_rain_losses).mean()\n",
    "    train_mean_temperature_loss = np.array(train_temperature_losses).mean()\n",
    "    print(f'Epoch {epoch} train loss: {train_mean_loss}. Temperature: {train_mean_temperature_loss}. Rain: {train_mean_rain_loss}.')\n",
    "        \n",
    "        \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_losses = []\n",
    "        val_rain_losses = []\n",
    "        val_t2m_losses = []\n",
    "        for example in val_dataloader:\n",
    "            model_tp_mu, model_tp_sigma = example['model_tp_mu'], example['model_t2m_sigma']\n",
    "            model_t2m_mu, model_t2m_sigma = example['model_t2m_mu'], example['model_t2m_sigma']\n",
    "            \n",
    "            t2m_dist, tp_dist = model(model_t2m_mu, model_t2m_sigma, model_tp_mu, model_tp_sigma)\n",
    "            \n",
    "            obs_t2m, obs_tp = example['obs_t2m'], example['obs_tp']\n",
    "            \n",
    "            tp_obs = example['obs_tp']\n",
    "            tp_nan_mask = tp_obs.isnan()\n",
    "            tp_obs[tp_nan_mask] = 0.0\n",
    "            tp_log_likelihood = tp_dist.log_prob(tp_obs)\n",
    "            tp_log_likelihood[tp_nan_mask] = 0.0\n",
    "\n",
    "            t2m_obs = example['obs_t2m']\n",
    "            t2m_nan_mask = t2m_obs.isnan()\n",
    "            t2m_obs[t2m_nan_mask] = 0.0\n",
    "            t2m_log_likelihood = t2m_dist.log_prob(t2m_obs)\n",
    "            t2m_log_likelihood[t2m_nan_mask] = 0.0\n",
    "            \n",
    "            val_rain_loss = -tp_log_likelihood.mean()\n",
    "            val_temperature_loss =  -t2m_log_likelihood.mean()\n",
    "            val_loss = val_rain_loss + val_temperature_loss\n",
    "            \n",
    "            val_rain_losses.append(val_rain_loss.detach())\n",
    "            val_t2m_losses.append(val_temperature_loss.detach())\n",
    "            val_losses.append(val_loss.detach())\n",
    "        \n",
    "        \n",
    "    val_mean_loss = np.array(val_losses).mean()\n",
    "    val_mean_rain_loss = np.array(val_rain_losses).mean()\n",
    "    val_mean_temperature_loss = np.array(val_t2m_losses).mean()\n",
    "    print(f'Epoch {epoch} val loss: {val_mean_loss}. Temperature: {val_mean_temperature_loss}. Rain: {val_mean_rain_loss}.')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_rain_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=model.t2m_mu_model.weights[1][~t2m_nan_mask[0,0]].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=model.t2m_mu_model.intercept[2][~t2m_nan_mask[0,0]].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=model.tp_mu_model.weights[2][~tp_nan_mask[0,0]].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=model.tp_mu_model.intercept[2][~tp_nan_mask[0,0]].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(model.tp_mu_model.intercept[2].detach().numpy() + model.tp_mu_model.weights[2].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "S2S Challenge",
   "language": "python",
   "name": "s2s"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
