{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model multiplexer\n",
    "\n",
    "Rework the linear model and wrap it into a model multiplexer, so that we can have one model per month-day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.distributions\n",
    "import torch.nn as nn\n",
    "import xarray as xr\n",
    "\n",
    "from crims2s.dataset import S2SDataset, TransformedDataset\n",
    "from crims2s.transform import CompositeTransform, AddBiweeklyDimTransform, AddMetadata, ExampleToPytorch\n",
    "from crims2s.util import ECMWF_FORECASTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = '***BASEDIR***/mlready/2021-08-08-test/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make transform to interface dataset w/ linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_estimator(dataset, dim=None):\n",
    "    dataset_mean = dataset.mean(dim=dim)\n",
    "    \n",
    "    if dim is None:\n",
    "        dim_sizes = [dataset.sizes[x] for x in dataset_mean.dims]\n",
    "    elif isinstance(dim, str):\n",
    "        dim_sizes = dataset.sizes[dim]\n",
    "    else:\n",
    "        dim_sizes = [dataset.sizes[x] for x in dim]\n",
    "    \n",
    "    n = np.prod(dim_sizes)\n",
    "    \n",
    "    return xr.ufuncs.sqrt(xr.ufuncs.square(dataset - dataset_mean).sum(dim=dim) / (n - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_to_distribution(model):   \n",
    "    model_tp_mean = model.tp.isel(lead_time=-1).mean(dim='realization').rename('tp_mu')\n",
    "    model_tp_std = std_estimator(model.tp.isel(lead_time=-1), dim='realization').rename('tp_sigma')\n",
    "    \n",
    "    model_t2m_mean = model.t2m.mean(dim=['lead_time', 'realization']).rename('t2m_mu')\n",
    "    model_t2m_std = std_estimator(model.t2m, dim=['lead_time', 'realization']).rename('t2m_sigma')\n",
    "    \n",
    "    return xr.merge([\n",
    "        model_tp_mean, model_tp_std, model_t2m_mean, model_t2m_std\n",
    "    ]).drop('lead_time').rename(biweekly_forecast='lead_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obs_to_biweekly(obs):\n",
    "    aggregate_obs_tp = obs.pr.sum(dim='lead_time', min_count=2).rename('tp')\n",
    "    aggregate_obs_t2m = obs.t2m.mean(dim='lead_time')\n",
    "    return xr.merge([aggregate_obs_tp, aggregate_obs_t2m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_model_adapter(example):\n",
    "    model = model_to_distribution(example['model'])\n",
    "    obs = obs_to_biweekly(example['obs'])\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'obs': obs\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_train_dataset = S2SDataset(DATASET, filter_str='0312.nc', include_features=False, years=list(range(2000,2017)))\n",
    "#raw_val_dataset = S2SDataset(DATASET, filter_str='0312.nc', include_features=False, years=list(range(2017,2020)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_re = re.compile('01[0-9]{2}.nc$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_dataset = S2SDataset(DATASET, include_features=False, name_filter=lambda x: filter_re.search(x), years=list(range(2000,2017)))\n",
    "raw_val_dataset = S2SDataset(DATASET, include_features=False, name_filter=lambda x: filter_re.search(x), years=list(range(2017,2020)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in raw_train_dataset[0]['model'].data_vars:\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_dataset[0]['model']['t2m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = CompositeTransform([AddBiweeklyDimTransform(), linear_model_adapter, AddMetadata(), ExampleToPytorch()])\n",
    "\n",
    "train_dataset = TransformedDataset(raw_train_dataset, transform)\n",
    "val_dataset = TransformedDataset(raw_val_dataset, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, num_workers=4, batch_size=None, batch_sampler=None)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, num_workers=4, batch_size=None, batch_sampler=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Callable, Any, Hashable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_batch = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelMultiplexer(nn.Module):\n",
    "    \"\"\"Dispatch the training examples to multiple models depending on the example.\n",
    "    For instance, we could use this to use a different model for every monthday forecast.\n",
    "    \n",
    "    Because it uses an arbitraty model for every sample, this module does not support batching.\n",
    "    To use it, it is recommended to disable automatic batching on the dataloader.\"\"\"\n",
    "    def __init__(self, key, models):\n",
    "        \"\"\"Args:\n",
    "            key: If a str, used as a key to fetch the model name from the example dict. \n",
    "                 If a callable, called on the example and should return to model name to use.\n",
    "            models: A mapping from model names to model instances. They keys should correspond to what is returned when applying key on the example.\"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        if isinstance(key, str):\n",
    "            self.key_fn = lambda x: x[key]\n",
    "        else:\n",
    "            self.key_fn = key\n",
    "            \n",
    "        self.models = nn.ModuleDict(models)\n",
    "        \n",
    "    def forward(self, example):      \n",
    "        model_name = self.key_fn(example)\n",
    "        model = self.models[model_name]\n",
    "        \n",
    "        return model(example)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel(nn.Module):\n",
    "    def __init__(self, *shape, fill_weights=0.0, fill_intercept=0.0):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.weights = nn.Parameter(torch.full(shape, fill_weights))\n",
    "        self.intercept = nn.Parameter(torch.full(shape, fill_intercept))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.intercept + self.weights * x + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TempPrecipEMOS(nn.Module):\n",
    "    def __init__(self, biweekly=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        shape = (3, 121, 240) if biweekly else (121, 240)\n",
    "        \n",
    "        self.tp_mu_model = LinearModel(*shape)\n",
    "        self.tp_sigma_model = LinearModel(*shape, fill_intercept=1.0)\n",
    "        \n",
    "        self.t2m_mu_model = LinearModel(*shape)\n",
    "        self.t2m_sigma_model = LinearModel(*shape, fill_intercept=1.0)\n",
    "        \n",
    "    def forward(self, example):\n",
    "        forecast_tp_mu, forecast_tp_sigma = example['model_tp_mu'], example['model_tp_sigma']\n",
    "        forecast_t2m_mu, forecast_t2m_sigma = example['model_t2m_mu'], example['model_t2m_sigma']\n",
    "        \n",
    "        tp_mu = self.tp_mu_model(forecast_tp_mu)\n",
    "        tp_sigma = self.tp_sigma_model(forecast_tp_sigma)\n",
    "        tp_sigma = torch.clip(tp_sigma, min=1e-6)\n",
    "\n",
    "        t2m_mu = self.t2m_mu_model(forecast_t2m_mu)\n",
    "        t2m_sigma = self.t2m_sigma_model(forecast_t2m_sigma)\n",
    "        t2m_sigma = torch.clip(t2m_sigma, min=1e-6)\n",
    "        \n",
    "        tp_dist = torch.distributions.Normal(loc=tp_mu, scale=tp_sigma)\n",
    "        t2m_dist = torch.distributions.Normal(loc=t2m_mu, scale=t2m_sigma)\n",
    "        \n",
    "        return t2m_dist, tp_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthdays = [f'{m:02}{d:02}' for m, d in ECMWF_FORECASTS]\n",
    "weekly_models = {monthday: TempPrecipEMOS(biweekly=True) for monthday in monthdays}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weekly_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(weekly_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthdays[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelMultiplexer('monthday', weekly_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for epoch in range(20):\n",
    "    train_losses = []\n",
    "    train_temperature_losses = []\n",
    "    train_rain_losses = []\n",
    "    \n",
    "    model.train()\n",
    "    for example in train_dataloader:\n",
    "        t2m_dist, tp_dist = model.forward(example)\n",
    "\n",
    "        tp_obs = example['obs_tp']\n",
    "        tp_nan_mask = tp_obs.isnan()\n",
    "        tp_obs[tp_nan_mask] = 0.0\n",
    "        tp_log_likelihood = tp_dist.log_prob(tp_obs)\n",
    "        tp_log_likelihood[tp_nan_mask] = 0.0\n",
    "\n",
    "        t2m_obs = example['obs_t2m']\n",
    "        t2m_nan_mask = t2m_obs.isnan()\n",
    "        t2m_obs[t2m_nan_mask] = 0.0\n",
    "        t2m_log_likelihood = t2m_dist.log_prob(t2m_obs)\n",
    "        t2m_log_likelihood[t2m_nan_mask] = 0.0\n",
    "\n",
    "        rain_loss = -tp_log_likelihood.mean()\n",
    "        temperature_loss =  -t2m_log_likelihood.mean()\n",
    "        loss = rain_loss + temperature_loss\n",
    "        \n",
    "        loss.backward()\n",
    "                \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        train_losses.append(float(loss.detach()))\n",
    "        train_temperature_losses.append(float(temperature_loss.detach()))\n",
    "        train_rain_losses.append(float(rain_loss.detach()))\n",
    "\n",
    "    train_mean_loss = np.array(train_losses).mean()\n",
    "    train_mean_rain_loss = np.array(train_rain_losses).mean()\n",
    "    train_mean_temperature_loss = np.array(train_temperature_losses).mean()\n",
    "    print(f'Epoch {epoch} train loss: {train_mean_loss}. Temperature: {train_mean_temperature_loss}. Rain: {train_mean_rain_loss}.')\n",
    "        \n",
    "        \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_losses = []\n",
    "        val_rain_losses = []\n",
    "        val_t2m_losses = []\n",
    "        for example in val_dataloader:\n",
    "            t2m_dist, tp_dist = model(example)\n",
    "            \n",
    "            obs_t2m, obs_tp = example['obs_t2m'], example['obs_tp']\n",
    "            \n",
    "            tp_obs = example['obs_tp']\n",
    "            tp_nan_mask = tp_obs.isnan()\n",
    "            tp_obs[tp_nan_mask] = 0.0\n",
    "            tp_log_likelihood = tp_dist.log_prob(tp_obs)\n",
    "            tp_log_likelihood[tp_nan_mask] = 0.0\n",
    "\n",
    "            t2m_obs = example['obs_t2m']\n",
    "            t2m_nan_mask = t2m_obs.isnan()\n",
    "            t2m_obs[t2m_nan_mask] = 0.0\n",
    "            t2m_log_likelihood = t2m_dist.log_prob(t2m_obs)\n",
    "            t2m_log_likelihood[t2m_nan_mask] = 0.0\n",
    "            \n",
    "            val_rain_loss = -tp_log_likelihood.mean()\n",
    "            val_temperature_loss =  -t2m_log_likelihood.mean()\n",
    "            val_loss = val_rain_loss + val_temperature_loss\n",
    "            \n",
    "            val_rain_losses.append(val_rain_loss.detach())\n",
    "            val_t2m_losses.append(val_temperature_loss.detach())\n",
    "            val_losses.append(val_loss.detach())\n",
    "        \n",
    "        \n",
    "    val_mean_loss = np.array(val_losses).mean()\n",
    "    val_mean_rain_loss = np.array(val_rain_losses).mean()\n",
    "    val_mean_temperature_loss = np.array(val_t2m_losses).mean()\n",
    "    print(f'Epoch {epoch} val loss: {val_mean_loss}. Temperature: {val_mean_temperature_loss}. Rain: {val_mean_rain_loss}.')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_rain_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in model.models:\n",
    "    print(k, model.models[k].tp_mu_model.weights[2][~t2m_nan_mask[0]].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicts = []\n",
    "\n",
    "masks = {\n",
    "    't2m': t2m_nan_mask[0],\n",
    "    'tp': tp_nan_mask[0],\n",
    "}\n",
    "\n",
    "for monthday in monthdays[:4]:\n",
    "    m = model.models[monthday]\n",
    "    \n",
    "    for parameter in ['mu', 'sigma']:\n",
    "        for variable in ['t2m', 'tp']:\n",
    "            attr_name = f'{variable}_{parameter}_model'\n",
    "            linear_model = getattr(m, attr_name)\n",
    "            mask = masks[variable]\n",
    "            \n",
    "            for component in ['weights', 'intercept']:\n",
    "                model_component = getattr(linear_model, component)\n",
    "                \n",
    "                for lead_time in [0, 1, 2]:\n",
    "                    at_lead_time = model_component[lead_time]\n",
    "                    masked = at_lead_time[~mask].detach().numpy()\n",
    "                \n",
    "                    datapoints = [{\n",
    "                        'monthday': monthday, \n",
    "                        'parameter': parameter,\n",
    "                        'variable': variable,\n",
    "                        'component': component,\n",
    "                        'lead_time': lead_time,\n",
    "                        'value': x\n",
    "                    } for x in masked]\n",
    "                    dicts.extend(datapoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthdays[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable in ['t2m', 'tp']:\n",
    "    for parameter in ['mu', 'sigma']:\n",
    "        for component in ['weights', 'intercept']:\n",
    "            title = f'Distribution of {variable} {parameter} {component}'\n",
    "            \n",
    "            fig = plt.gcf()\n",
    "            fig.set_size_inches(6,4)\n",
    "            ax = sns.kdeplot(data=df[(df['component'] == component) & (df['variable'] == variable) & (df['parameter'] == parameter)], x='value', hue='lead_time')\n",
    "            ax.set_title(title)\n",
    "            plt.savefig(title.replace(' ', '_') + '.png')\n",
    "            plt.show()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=df[(df['component'] == 'weights') & (df['variable'] == 't2m') & (df['parameter'] == 'mu')], x='value', row='lead_time').set_title('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df[(df['parameter'] == 'mu') & (df['variable'] == 't2m') & (df['lead_time'] == 0) & (df['component'] == 'intercept')], x='value',hue='monthday')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=model.models['0123'].tp_mu_model.intercept[2][~tp_nan_mask[0]].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=model.models['0123'].tp_mu_model.weights[1][~tp_nan_mask[0]].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=model.models['0123'].tp_sigma_model.intercept[1][~tp_nan_mask[0]].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=model.models['0123'].tp_sigma_model.weights[1][~tp_nan_mask[0]].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=model.models['0123'].t2m_sigma_model.weights[1][~t2m_nan_mask[0]].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=model.models['0123'].t2m_sigma_model.intercept[1][~t2m_nan_mask[0]].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=model.models['0123'].t2m_mu_model.intercept[1][~t2m_nan_mask[0]].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=model.models['0123'].t2m_mu_model.weights[1][~t2m_nan_mask[0]].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "S2S Challenge",
   "language": "python",
   "name": "s2s"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
