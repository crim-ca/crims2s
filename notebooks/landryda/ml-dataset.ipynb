{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Dataset\n",
    "\n",
    "First attempt at an ML dataset.\n",
    "Here one example will be one forecast date, and the corresponding observations.\n",
    "\n",
    "We will use Arlan's top ten as features: https://docs.google.com/spreadsheets/d/1CzNvLExxJYhFAS_bWs97DON2xpG3zmDt-HHwQhqjpkE/edit#gid=0.\n",
    "\n",
    "- *Surface Air Temperature (at 2 meter)*\n",
    "- *Total precipitation*\n",
    "- Soil moisture top 20 cm\n",
    "- Snow Depth Water equivalent\n",
    "- Sea Surface Temperature\n",
    "- Sea Ice Cover\n",
    "- Mean Sea Level Pressure\n",
    "- Geopotential height@ 1000 hPa\n",
    "- Geopotential height@ 200 hPa\n",
    "- U-velocity (aka Zonal wind )@ 200 hPa\n",
    "- U-velocity (aka Zonal wind )@ 850 hPa\n",
    "- V-velocity (Meridional wind)@ 200 hPa\n",
    "- V-velocity (Meridional wind)@ 850 hPa\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.distributed\n",
    "import logging\n",
    "import pathlib\n",
    "import xarray as xr\n",
    "\n",
    "from crims2s.data import normalize_dataset\n",
    "from crims2s.dask import create_dask_cluster\n",
    "from crims2s.util import fix_dataset_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize dask cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = create_dask_cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = dask.distributed.Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DATA = '***BASEDIR***/training-input/'\n",
    "INPUT_DATA_SPLIT_PLEV = '***BASEDIR***processed/training-input'\n",
    "OBS_DATA = '***BASEDIR***/processed/training-output-reference/'\n",
    "OBS_FILE_TEST = '***BASEDIR***/renku/forecast-like-observations_2020_biweekly_terciled.nc'\n",
    "TRAIN_OBS = '***BASEDIR***/renku/hindcast-like-observations_2000-2019_biweekly_terciled.nc'\n",
    "OUTPUT_DIR = '***BASEDIR***/training/2021-07-24-first'\n",
    "\n",
    "\n",
    "CENTER = 'ecmwf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = pathlib.Path(OUTPUT_DIR)\n",
    "output_path.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAT_FIELDS = ['t2m', 'tp', 'sm20', 'sst', 'ci', 'msl']\n",
    "MULTILEVEL_FIELDS = [('u', [200, 850]), ('v', [200, 850]), ('gh', [1000, 200])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = xr.open_dataset('***BASEDIR***processed/training-input/ecmwf-hindcast-u200-20200528.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.plev[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_d = d\n",
    "for var in d.data_vars:\n",
    "    level = int(d.plev[0])\n",
    "    new_d = new_d.rename({var: f'{var}{level}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level = int(d.plev[0])\n",
    "new_names = {k: f'{k}{level}' for k in d.data_vars}\n",
    "new_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.rename(new_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_obs_terciled.to_array().isel(forecast_time=0, category=0, lead_time=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_single_level_file(d):\n",
    "    level = int(d.plev[0])\n",
    "    new_names = {k: f'{k}{level}' for k in d.data_vars}\n",
    "    \n",
    "    return d.rename(new_names).isel(plev=0).drop('plev')\n",
    "\n",
    "def process_one_forecast_week(datestring, obs_terciled):\n",
    "    filenames = [f'{INPUT_DATA}/{CENTER}-hindcast-{f}-{forecast_times[0]}.nc' for f in flat_fields]\n",
    "    \n",
    "    # Flat fields.\n",
    "    _logger.debug('Opening flat fields')\n",
    "    flat_dataset = xr.open_mfdataset(filenames, preprocess=fix_dataset_dims).isel(depth_below_and_layer=0, meanSea=0).drop(['depth_below_and_layer', 'meanSea'])\n",
    "    \n",
    "    # Non-flat fields.\n",
    "    _logger.debug('Opening larger fields')\n",
    "    flattened_fields = []\n",
    "    for field, levels in multilevel_fields:\n",
    "        files = [f'{INPUT_DATA_SPLIT_PLEV}/{CENTER}-hindcast-{field}{level}-{forecast_times[0]}.nc' for level in levels]\n",
    "        _logger.debug(f'Opening multi-level fields: {files}')\n",
    "        ds = xr.open_mfdataset(files, preprocess=preprocess_single_level_file)\n",
    "        flattened_fields.append(ds)\n",
    "            \n",
    "    # Merge the two.\n",
    "    ds = normalize_dataset(xr.merge([*flattened_fields, flat_dataset]))\n",
    "    ds = ds.persist()\n",
    "    \n",
    "    # Export all years separately.\n",
    "    examples = []\n",
    "    for i in range(ds.dims['forecast_year']):\n",
    "        print(i)\n",
    "        to_export_x = ds.isel(forecast_year=i, forecast_dayofyear=0).to_array().rename('x').transpose('lead_time', 'latitude', 'longitude', 'realization', 'variable')\n",
    "        to_export_y = obs_terciled.sel(forecast_time=to_export_x.forecast_time).to_array().rename('y').transpose('latitude', 'longitude', 'variable', 'lead_time', 'category')\n",
    "        examples.append((to_export_x, to_export_y))\n",
    "    \n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_obs_terciled = xr.open_dataset(TRAIN_OBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = pathlib.Path(INPUT_DATA)\n",
    "forecast_times = [x.stem.split('-')[-1] for x in input_path.iterdir() if 't2m' in x.stem and CENTER in x.stem]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = process_one_forecast_week(forecast_times[0], train_obs_terciled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples[10][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in examples:\n",
    "    forecast_time = y.forecast_time\n",
    "    year = int(forecast_time.dt.year)\n",
    "    month = int(forecast_time.dt.month)\n",
    "    day = int(forecast_time.dt.day)\n",
    "    filename = f'train_example_{year:04}{month:02}{day:02}.nc'\n",
    "    \n",
    "    output_file = output_path / filename\n",
    "    \n",
    "    x.to_netcdf(output_file, group='/x', mode='w')\n",
    "    y.to_netcdf(output_file, group='/y', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.isel(variable=0, lead_time=0, category=0).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh {OUTPUT_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstt = xr.open_dataset(output_file, group='/y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_times[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [f'{INPUT_DATA}/{CENTER}-hindcast-{f}-{forecast_times[0]}.nc' for f in flat_fields]\n",
    "flat_dataset = xr.open_mfdataset(filenames, preprocess=fix_dataset_dims).isel(depth_below_and_layer=0, meanSea=0).drop(['depth_below_and_layer', 'meanSea'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_fields = []\n",
    "\n",
    "for field, levels in multilevel_fields:\n",
    "    filename = f'{INPUT_DATA}/{CENTER}-hindcast-{field}-{forecast_times[0]}.nc'\n",
    "    ds = fix_dataset_dims(xr.open_dataset(filename))\n",
    "    print(ds)\n",
    "    for level in levels:\n",
    "        flattened_fields.append(ds.sel(plev=level).drop('plev').rename({field: f'{field}{level}'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_dataset = xr.merge(flattened_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = normalize_dataset(xr.merge([flattened_dataset, flat_dataset]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.mean().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.std().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make examples from bigger dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_export_x = ds.isel(forecast_year=0).to_array().isel(forecast_dayofyear=0).transpose('lead_time', 'latitude', 'longitude', 'realization', 'variable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_export_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_export_x.to_netcdf('***BASEDIR***/mldataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Already terciled observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_OBS = '***BASEDIR***/renku/hindcast-like-observations_2000-2019_biweekly_terciled.nc'\n",
    "train_obs_terciled = xr.open_dataset(TRAIN_OBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_obs_terciled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "S2S Challenge",
   "language": "python",
   "name": "s2s"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
