{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn Gamma\n",
    "\n",
    "The objective is to fit one gamma distribution per lat-lon to model the precipitation distribution of a tile.\n",
    "First, we study the Gamma distribution object from pytorch to learn how tu use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import torch\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import xarray as xr\n",
    "\n",
    "from crims2s.util import fix_dataset_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = torch.distributions.Gamma(torch.Tensor([5.0]), torch.Tensor([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = d.sample((1000,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'value': sample.numpy()[:,0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_hat = sample.mean() ** 2 / sample.var()\n",
    "b_hat = sample.var() / sample.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a = torch.full((1,), a_hat, requires_grad=True)\n",
    "b = torch.full((1,), b_hat, requires_grad=True)\n",
    "\n",
    "#a = torch.rand((1,), requires_grad=True)\n",
    "#b = torch.rand((1,), requires_grad=True)\n",
    "\n",
    "optimizer = torch.optim.SGD([a,b], lr=1e-2, momentum=0)\n",
    "\n",
    "losses = []\n",
    "a_list = []\n",
    "b_list = []\n",
    "mean_lls = []\n",
    "regs = []\n",
    "\n",
    "lambd = 1e-10\n",
    "\n",
    "for _ in range(1000):\n",
    "    estimated_gamma = torch.distributions.Gamma(torch.clamp(a, min=1e-6) , torch.clamp(b, min=1e-6))\n",
    "    \n",
    "    mean_log_likelihood = (1.0 - lambd) * estimated_gamma.log_prob(sample).mean()\n",
    "    regularization = lambd * torch.square(a+b)\n",
    "    \n",
    "    mean_lls.append(mean_log_likelihood.detach().item())\n",
    "    regs.append(regularization.detach().item())\n",
    "    \n",
    "    loss = -1.0 * mean_log_likelihood + regularization    \n",
    "    a_list.append(a.detach().item())\n",
    "    b_list.append(b.detach().item())\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    losses.append(loss.detach().item())\n",
    "    \n",
    "print(a.detach().item())\n",
    "print(b.detach().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(a_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(b_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mean_lls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(regs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do it for our real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OBS_DIR = '***BASEDIR***training-output-reference/'\n",
    "obs_path = pathlib.Path(OBS_DIR)\n",
    "\n",
    "obs_files = sorted([f for f in obs_path.iterdir() if 'tp' in f.stem])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tp = xr.open_mfdataset(obs_files, preprocess=fix_dataset_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_w34 = (tp.sel(lead_time='28D') - tp.sel(lead_time='14D')).sel(latitude=slice(50.0, 30.0), forecast_dayofyear=slice(60, 220), forecast_year=slice(2007, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_w34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_w34.isnull().sum(dim=['latitude', 'longitude']).tp.compute().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_w34 = tp_w34.stack(station=('latitude', 'longitude'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_w34.dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_ids = xr.DataArray(np.arange(tp_w34.dims['station']), dims='station_coords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_w34 = tp_w34.rename(station='station_coords').assign_coords(station=station_ids).swap_dims(station_coords='station')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tp_w34 = tp_w34.drop('station_coords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_w34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_mask = (tp_w34.isnull().sum(dim=['forecast_year', 'forecast_dayofyear']) == 0).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_w34_only_land = tp_w34.where(station_mask, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_w34_only_land"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_train = tp_w34_only_land.isel(forecast_year=slice(None, -3))\n",
    "tp_val = tp_w34_only_land.isel(forecast_year=slice(-3, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_hat_xarray = tp_train.mean(dim='forecast_year') ** 2 / (tp_train.var(dim='forecast_year') + 1e-6)\n",
    "b_hat_xarray = (tp_train.mean(dim='forecast_year') + 1e-6) / (tp_train.var(dim='forecast_year') + 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_hat_xarray.isnull().compute().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pytorch = torch.tensor(tp_train.tp.data.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pytorch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pytorch = torch.tensor(tp_val.tp.data.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pytorch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pytorch.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pytorch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_hat = torch.tensor(a_hat_xarray.tp.data.compute(), requires_grad=True, device='cuda')\n",
    "b_hat = torch.tensor(b_hat_xarray.tp.data.compute(), requires_grad=True, device='cuda')\n",
    "\n",
    "#a_hat = torch.rand(*train_pytorch.shape[1:], requires_grad=True)\n",
    "#b_hat = torch.rand(*train_pytorch.shape[1:], requires_grad=True)\n",
    "\n",
    "optimizer = torch.optim.SGD([a_hat,b_hat], lr=1e-2, momentum=0.0)\n",
    "\n",
    "losses = []\n",
    "a_list = []\n",
    "b_list = []\n",
    "mean_lls = []\n",
    "regs = []\n",
    "vals = []\n",
    "\n",
    "true_train = []\n",
    "true_val = []\n",
    "\n",
    "\n",
    "train_pytorch = torch.tensor(tp_train.tp.data.compute()).cuda()\n",
    "val_pytorch = torch.tensor(tp_val.tp.data.compute()).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambd = 0.01\n",
    "optimizer = torch.optim.SGD([a_hat,b_hat], lr=5.0, momentum=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2000):\n",
    "    estimated_gamma = torch.distributions.Gamma(torch.clamp(a_hat, min=1e-6) , torch.clamp(b_hat, min=1e-6))\n",
    "    \n",
    "    mean_log_likelihood = (1.0 - lambd) * estimated_gamma.log_prob(train_pytorch + 1e-6).mean()\n",
    "    regularization = lambd * (torch.square(a_hat) + torch.square(b_hat)).mean()\n",
    "    \n",
    "    mean_lls.append(-mean_log_likelihood.detach().item())\n",
    "    regs.append(regularization.detach().item())\n",
    "    \n",
    "    loss = -1.0 * mean_log_likelihood + regularization    \n",
    "\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    val_mean_log_likelihood = (1.0 - lambd) * estimated_gamma.log_prob(val_pytorch + 1e-6).mean()\n",
    "    \n",
    "    losses.append(loss.detach().item())\n",
    "    vals.append(-val_mean_log_likelihood.detach().item())\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        a_list.append(a_hat.mean().detach().item())\n",
    "        b_list.append(b_hat.mean().detach().item())\n",
    "    \n",
    "    true_train.append(estimated_gamma.log_prob(train_pytorch + 1e-6).mean().detach().item())\n",
    "    true_val.append(estimated_gamma.log_prob(val_pytorch + 1e-6).mean().detach().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_gamma.log_prob(train_pytorch + 1e-6)[:, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plt.plot(true_train)\n",
    "plt.plot(true_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin = 0\n",
    "end = -1\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(mean_lls[begin:end], label='train')\n",
    "ax.plot(vals[begin:end], label='val')\n",
    "ax.plot(regs[begin:end], label='reg')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(a_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(b_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(regs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(a_hat < 0.0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_hat.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_hat.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_hat.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pytorch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pytorch[:, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pytorch.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_hat.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_hat.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_hat[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_hat[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.distributions.Gamma(a_hat[0,0], b_hat[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.log_prob(train_pytorch[:,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = torch.exp(g.log_prob(torch.arange(1e-6, 50)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pdf.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_hat[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy_g = scipy.stats.gamma(a=0.4462, scale=1 / 0.0194)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix, ax = plt.subplots()\n",
    "ax.plot(pdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, loc, scale = scipy.stats.gamma.fit(train_pytorch[:, 0, 0].detach().cpu().numpy())\n",
    "scipy_g = scipy.stats.gamma(a=1.5, scale=0.0681)\n",
    "pdfs = scipy_g.pdf(np.arange(0.1, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pytorch[:, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy_g.pdf(train_pytorch[:, 0, 0].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_hat[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do it on only one station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = tp_train.isel(station=0, forecast_dayofyear=0).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_hat_xarray = (sample.mean(dim='forecast_year') ** 2 / (sample.var(dim='forecast_year') + 1e-6)).compute().tp.data\n",
    "b_hat_xarray = ((sample.mean(dim='forecast_year') / sample.var(dim='forecast_year') + 1e-6)).compute().tp.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_hat_xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_hat_xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_hat = torch.tensor(a_hat_xarray, requires_grad=True)\n",
    "b_hat =  torch.tensor(b_hat_xarray, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.distributions.Gamma(a_hat, b_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.log_prob(sample.tp.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "S2S Challenge",
   "language": "python",
   "name": "s2s"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
