{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributions of parameters\n",
    "\n",
    "For every field that we want to use as input for deep learning, plot their distributions, so that we know what kind of normalization to apply.\n",
    "I expect that we will mostly have normal distritbutions (or use normal distritbutions even though we shouldn't)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boot dask cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.array as da\n",
    "import dask.distributed\n",
    "import dask_jobqueue\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import scipy.stats\n",
    "import xarray as xr\n",
    "import xskillscore as xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crims2s.util import fix_dataset_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_TRAIN = '***BASEDIR***training-input/0.3.0/netcdf'\n",
    "INPUT_PROCESSED = '***BASEDIR***processed/training-input/'\n",
    "OBSERVATIONS = '***BASEDIR***training-output-reference/'\n",
    "BENCHNMARK = '***BASEDIR***training-output-benchmark/'\n",
    "CENTER = 'ecmwf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = pathlib.Path(INPUT_TRAIN)\n",
    "obs_path = pathlib.Path(OBSERVATIONS)\n",
    "processed_path = pathlib.Path(INPUT_PROCESSED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boost dask cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = dask_jobqueue.SLURMCluster(\n",
    "    env_extra=['source ***HOME***.bash_profile','conda activate s2s'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(jobs=6)  # Scale to two working nodes as configured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = dask.distributed.Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surface temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIELD = 't2m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_files = sorted([f for f in input_path.iterdir() if CENTER in f.stem and FIELD in f.stem])\n",
    "ecmwf = xr.open_mfdataset(field_files, preprocess=fix_dataset_dims)\n",
    "ecmwf = ecmwf.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Overall mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2m_mean = ecmwf.t2m.mean().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2m_std = ecmwf.t2m.std().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2m_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2m_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check shape of distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecmwf.t2m.isel(forecast_year=10).plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not as gaussian as I'd like but for now a normal will do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check yearly progression\n",
    "\n",
    "Should we adjust for climate change correlation?\n",
    "Ideally we would do this on a tile by tile basis (and look for a correlation between year and average temperature).\n",
    "If there is a strong correlation, one way or the other, we should adjust for temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecmwf.dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_means = ecmwf.t2m.mean(dim=['realization', 'forecast_dayofyear', 'lead_time', 'latitude', 'longitude']).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_means.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trend is pretty clear! But it's about 1 degree over our training dataset. Given that temperture had a std of about 20, i'm not sure it matters enough to be priority.\n",
    "\n",
    "Also, our models will be boosting models, so if the model incorporates this trend there could be double accounting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_files = [f for f in obs_path.iterdir() if FIELD in f.stem]\n",
    "obs = xr.open_mfdataset(obs_files, preprocess=fix_dataset_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_yearly_means = obs.t2m.mean(dim=['forecast_dayofyear', 'lead_time', 'latitude', 'longitude']).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_yearly_means.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ecmwf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIELD = '-t-'\n",
    "field_files = sorted([f for f in input_path.iterdir() if CENTER in f.stem and FIELD in f.stem])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_files[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecmwf = fix_dataset_dims(xr.open_dataset(field_files[0], chunks={'plev': 1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecmwf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecmwf = xr.open_mfdataset(field_files, preprocess=fix_dataset_dims, chunks={'plev': 1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecmwf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_plev = ecmwf.mean(dim=['latitude', 'longitude']).persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_plev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del by_plev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = by_plev.compute()\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecmwf = ecmwf.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecmwf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask.config.get('array.chunk-size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_mean = ecmwf.mean().compute()\n",
    "t_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_std = ecmwf.mean().compute()\n",
    "t_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precipitation\n",
    "\n",
    "For precipitation we will do our lienar rescaling over 2 weeks since the provided data is accumulated precipitation.\n",
    "To the mean will be mean total precipitation over 2 weeks, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIELD = 'tp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_files = sorted([f for f in input_path.iterdir() if CENTER in f.stem and f'-{FIELD}-' in f.stem])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_files[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecmwf = xr.open_mfdataset(field_files, preprocess=fix_dataset_dims)\n",
    "ecmwf = ecmwf.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecmwf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w12 = ecmwf.isel(lead_time=14).drop('valid_time')\n",
    "w34 = ecmwf.isel(lead_time=28) - w12\n",
    "w56 = ecmwf.isel(lead_time=42) - ecmwf.isel(lead_time=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads = [datetime.timedelta(days=x) for x in [14, 28, 42]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = xr.concat([w12, w34, w56], dim='lead_time').assign_coords(lead_time=xr.DataArray(data=leads, dims='lead_time'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp.mean(dim=['latitude', 'longitude', 'realization', 'forecast_dayofyear', 'forecast_year']).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_mean = tp.mean().compute()\n",
    "tp_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_std = tp.std().compute()\n",
    "tp_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Overall mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_mean = ecmwf.tp.mean().compute()\n",
    "tp_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_std = ecmwf.tp.std().compute()\n",
    "tp_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecmwf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecmwf.isel(forecast_dayofyear=0, forecast_year=0, latitude=40, longitude=10).mean(dim=['realization']).tp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geopotential Height\n",
    "\n",
    "We read this field from the processed dir instead of the input dir.\n",
    "Consequently there is no need for fix_dataset_dims we already did that when procesing the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHTS = [100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for h in HEIGHTS:\n",
    "    FIELD = f'-gh{h}-'\n",
    "    field_files = sorted([f for f in processed_path.iterdir() if CENTER in f.stem and FIELD in f.stem])\n",
    "    print(f'{len(field_files)} files.')\n",
    "    ecmwf = xr.open_mfdataset(field_files)\n",
    "    ecmwf = ecmwf.persist()\n",
    "    mean = ecmwf.mean().compute().gh.item()\n",
    "    std = ecmwf.std().compute().gh.item()\n",
    "    del ecmwf\n",
    "    print(f'GH{h}. Mean: {mean}. STD: {std}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_files = sorted([f for f in processed_path.iterdir() if CENTER in f.stem and FIELD in f.stem])\n",
    "ecmwf = xr.open_mfdataset(field_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ecmwf.isel(lead_time=0).gh.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client.restart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sea Surface Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.restart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIELD = 'sst'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_files = sorted([f for f in input_path.iterdir() if CENTER in f.stem and FIELD in f.stem])\n",
    "ecmwf = xr.open_mfdataset(field_files, preprocess=fix_dataset_dims)\n",
    "ecmwf = ecmwf.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Overall mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_mean = ecmwf.sst.mean().compute()\n",
    "sst_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_std = ecmwf.sst.std().compute()\n",
    "sst_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "S2S Challenge",
   "language": "python",
   "name": "s2s"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
