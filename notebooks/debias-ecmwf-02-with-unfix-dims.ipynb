{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unbiased ECMWF\n",
    "\n",
    "Here we propose a small model which is a debiased ECMWF forecast according to the data we have.\n",
    "The plan is\n",
    "* Compute the bias between the ECMWF model and the observations\n",
    "* Make a debiased model\n",
    "* Turn this model into a probabilistic forecast\n",
    "* Score the forecast\n",
    "For now we do it only on temperature and weeks 3-4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.array as da\n",
    "import dask.distributed\n",
    "import dask_jobqueue\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import scipy.stats\n",
    "import xarray as xr\n",
    "import xskillscore as xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crims2s.util import fix_dataset_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_TRAIN = '***BASEDIR***training-input/0.3.0/netcdf'\n",
    "OBSERVATIONS = '***BASEDIR***training-output-reference/'\n",
    "BENCHNMARK = '***BASEDIR***training-output-benchmark/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boost dask cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_dask(user: str = \"landryda\", jobs: int = 2):\n",
    "    \n",
    "    if user == \"landryda\":\n",
    "        cluster = dask_jobqueue.SLURMCluster(env_extra=['source ***HOME***.bash_profile','conda activate s2s'])\n",
    "    elif user == \"gierscjo\":\n",
    "        cluster = dask_jobqueue.SLURMCluster(cores=12,\n",
    "                                             processes=6,\n",
    "                                             memory='128G',\n",
    "                                             env_extra=['source ***HOME***.bash_profile','conda activate s2s'],\n",
    "                                             name='agri-dask',\n",
    "                                             local_directory='***CACHE***', # METTRE VOTRE LOGIN CRIM ICI\n",
    "                                             walltime='3:00:00')\n",
    "    \n",
    "    cluster.scale(jobs=jobs)  # Scale to two working nodes as configured.\n",
    "    \n",
    "    return dask.distributed.Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = start_dask(user=\"gierscjo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generic Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_train_validation_from_lead_time(xr_data, time_slice: slice = slice('14D', '27D')) -> Tuple:\n",
    "    \n",
    "    xr_data_sub = xr_data.sel(lead_time=time_slice)\n",
    "    xr_data_sub_train = xr_data_sub.sel(forecast_year=slice(None, 2018))\n",
    "    xr_data_sub_val = xr_data_sub.sel(forecast_year=slice(2019, None))\n",
    "    \n",
    "    return xr_data_sub, xr_data_sub_train, xr_data_sub_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_and_correct_bias(data_center_train, data_center_val, obs_train):\n",
    "    \n",
    "    bias = (obs_train - data_center_train).mean(dim=['lead_time', 'forecast_year'])\n",
    "    corrected_bias = data_center_val + bias\n",
    "    \n",
    "    return bias, corrected_bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ECMWF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CENTER = 'ecmwf'\n",
    "FIELD = 't2m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = pathlib.Path(INPUT_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files = sorted([f for f in input_path.iterdir() if CENTER in f.stem and FIELD in f.stem])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecmwf = xr.open_mfdataset(input_files, preprocess=fix_dataset_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecmwf_w34 = ecmwf.sel(lead_time=slice('14D', '27D'))\n",
    "ecmwf_w34_train = ecmwf_w34.sel(forecast_year=slice(None, 2018))\n",
    "ecmwf_w34_val = ecmwf_w34.sel(forecast_year=slice(2019, None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ecmwf_w34, ecmwf_w34_train, ecmwf_w34_val = extract_train_validation_from_lead_time(ecmwf, time_slice=slice('14D', '27D'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ecmwf_w34_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ecmwf_w34_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_path = pathlib.Path(OBSERVATIONS)\n",
    "obs_files = [f for f in obs_path.iterdir() if 't2m' in f.stem]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = xr.open_mfdataset(obs_files, preprocess=fix_dataset_dims).isel(lead_time=slice(1, None))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "obs_w34, obs_w34_train, obs_w34_val = extract_train_validation_from_lead_time(obs, time_slice=slice('14D', '27D'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_w34_train = obs_w34.sel(forecast_year=slice(None, 2018))\n",
    "obs_w34_val = obs_w34.sel(forecast_year=slice(2019, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_w34_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debiasing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute bias using training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecmwf_w34_bias = (obs_w34_train - ecmwf_w34_train).mean(dim=['lead_time', 'forecast_year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias correct ECMWF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecmwf_w34_val_corrected = ecmwf_w34_val + ecmwf_w34_bias"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ecmwf_w34_bias, ecmwf_w34_val_corrected = compute_and_correct_bias(data_center_train=ecmwf_w34_train,\n",
    "                                                                   data_center_val=ecmwf_w34_val, \n",
    "                                                                   obs_train=obs_w34_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ecmwf_w34_bias"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Turn into probabilistic forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get thresholds from train observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_w34_train_thresholds = obs_w34_train.quantile([0.33, 0.67], dim=['lead_time', 'forecast_year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_w34_train_thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute p of thresholds according to the model\n",
    "\n",
    "There are two ways to do this. \n",
    "We can either count the amount of members that are whithin each category.\n",
    "Or compute a distribution of all the members of the model, and then compute the value of the CDF for each threshold.\n",
    "\n",
    "Here we do it using the distribution method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute a distribution of the members of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecmwf_w34_val_corrected_mean = ecmwf_w34_val_corrected.mean(dim=['realization', 'lead_time'])\n",
    "ecmwf_w34_val_corrected_std = ecmwf_w34_val_corrected.std(dim=['realization', 'lead_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the value of the CDF for each threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecmwf_w34_val_corrected_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_probabilistic(forecast, obs):\n",
    "    thresholds = obs.quantile([0.33, 0.67], dim=['lead_time', 'forecast_year'])\n",
    "    \n",
    "    loc = forecast.mean(dim=['realization', 'lead_time']).compute().t2m\n",
    "    scale = forecast.std(dim=['realization', 'lead_time']).compute().t2m\n",
    "    \n",
    "    cdfs = xr.apply_ufunc(scipy.stats.norm.cdf, thresholds.t2m, dask='allowed', kwargs={'loc': loc, 'scale': scale})\n",
    "    \n",
    "    below = cdfs.isel(quantile=0).drop_vars('quantile')\n",
    "    normal = (cdfs.isel(quantile=1) - cdfs.isel(quantile=0))\n",
    "    above = xr.ones_like(normal) - cdfs.isel(quantile=1).drop_vars('quantile')\n",
    "    \n",
    "    return xr.concat([below, normal, above], 'category').assign_coords(category=['below normal', 'near normal', 'above normal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_probabilistic_forecast = make_probabilistic(ecmwf_w34_val_corrected, obs_w34_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_probabilistic_forecast.isel(category=2, forecast_dayofyear=40).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_probabilistic_forecast.isel(category=1, forecast_dayofyear=40).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = ecmwf_w34_val_corrected_mean.compute().t2m\n",
    "scale = ecmwf_w34_val_corrected_std.compute().t2m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdfs = xr.apply_ufunc(scipy.stats.norm.cdf, obs_w34_train_thresholds.t2m, dask='allowed', kwargs={'loc': loc, 'scale': scale})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdfs.isel(quantile=1).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "below = cdfs.isel(quantile=0).drop_vars('quantile')\n",
    "normal = (cdfs.isel(quantile=1) - cdfs.isel(quantile=0))\n",
    "above = xr.ones_like(normal) - cdfs.isel(quantile=1).drop_vars('quantile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_probabilistic_forecast = xr.concat([below, normal, above], 'category', coords='minimal').assign_coords(category=['below normal', 'near normal', 'above normal'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_probabilistic_forecast.sum(dim='category').isel(forecast_dayofyear=0).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a probabilistic version of the val obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_w34_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = obs_w34_val.mean(dim=['lead_time']).compute().t2m\n",
    "scale = obs_w34_val.std(dim=['lead_time']).compute().t2m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdfs = xr.apply_ufunc(scipy.stats.norm.cdf, obs_w34_train_thresholds.t2m, dask='allowed', kwargs={'loc': loc, 'scale': scale})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "below = cdfs.isel(quantile=0).drop_vars('quantile')\n",
    "normal = (cdfs.isel(quantile=1) - cdfs.isel(quantile=0))\n",
    "above = xr.ones_like(normal) - cdfs.isel(quantile=1).drop_vars('quantile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_probabilistic_obs = xr.concat([below, normal, above], 'category').assign_coords(category=['below normal', 'near normal', 'above normal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_probabilistic_obs.isel(category=2, forecast_dayofyear=0).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare both proba using rps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_probabilistic_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs.rps(val_probabilistic_obs, val_probabilistic_forecast, category_edges=None, input_distributions='p', dim=['forecast_dayofyear']).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_probabilistic_obs.isel(forecast_dayofyear=0, category=2).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_probabilistic_forecast.isel(forecast_dayofyear=0, category=2).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process week 5-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecmwf_w56, ecmwf_w56_train, ecmwf_w56_val = extract_train_validation_from_lead_time(ecmwf, time_slice=slice('28D', '41D'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_w56, obs_w56_train, obs_w56_val = extract_train_validation_from_lead_time(obs, time_slice=slice('28D', '41D'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecmwf_w56_bias, ecmwf_w56_val_corrected = compute_and_correct_bias(data_center_train=ecmwf_w56_train,\n",
    "                                                                   data_center_val=ecmwf_w56_val, \n",
    "                                                                   obs_train=obs_w56_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_w56_train_thresholds = obs_w56_train.quantile([0.33, 0.66], dim=['lead_time', 'forecast_year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecmwf_w56_val_corrected_mean = ecmwf_w56_val_corrected.mean(dim=['realization', 'lead_time'])\n",
    "ecmwf_w56_val_corrected_std = ecmwf_w56_val_corrected.std(dim=['realization', 'lead_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_probabilistic_forecast_w56 = make_probabilistic(ecmwf_w56_val_corrected, obs_w56_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_probabilistic_forecast_w56.isel(category=2, forecast_dayofyear=40).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_w56 = ecmwf_w56_val_corrected_mean.compute().t2m\n",
    "scale_w56 = ecmwf_w56_val_corrected_std.compute().t2m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdfs_w56 = xr.apply_ufunc(scipy.stats.norm.cdf, obs_w56_train_thresholds.t2m, dask='allowed', kwargs={'loc': loc, 'scale': scale})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "below_w56 = cdfs_w56.isel(quantile=0).drop_vars('quantile')\n",
    "normal_w56 = (cdfs_w56.isel(quantile=1) - cdfs_w56.isel(quantile=0))\n",
    "above_w56 = xr.ones_like(normal) - cdfs_w56.isel(quantile=1).drop_vars('quantile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_probabilistic_obs_w56 = xr.concat([below_w56, normal_w56, above_w56], 'category').assign_coords(category=['below normal', 'near normal', 'above normal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_probabilistic_obs_w56.isel(category=2, forecast_dayofyear=0).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs.rps(val_probabilistic_obs_w56, val_probabilistic_forecast, category_edges=None, input_distributions='p', dim=['latitude', 'longitude']).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_path = sorted([f for f in pathlib.Path(BENCHNMARK).iterdir() if FIELD in f.stem])[-1]\n",
    "benchmark_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_example = xr.open_mfdataset([benchmark_path], preprocess=fix_dataset_dims)\n",
    "benchmark_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_probabilistic_obs_all = xr.concat([val_probabilistic_obs, val_probabilistic_obs_w56], \"lead_time\").to_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_probabilistic_obs_all = val_probabilistic_obs_all.assign_coords(lead_time=np.array([14, 28], dtype='timedelta64[D]'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_probabilistic_obs_all.attrs = benchmark_example.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_probabilistic_obs_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "S2S Challenge",
   "language": "python",
   "name": "s2s"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
