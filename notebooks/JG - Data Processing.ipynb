{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c3a531b-5538-4fb1-957e-021945ab2f3d",
   "metadata": {},
   "source": [
    "# S2S Competition - Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ac2fb1-4dac-49af-936b-82d5924a4c9d",
   "metadata": {},
   "source": [
    "## Notebook configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bc75fa-969e-462b-9aaf-89b8fa03a521",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOT_DASK_CLUSTER: bool = False\n",
    "    \n",
    "INPUT_DATA: str = '***BASEDIR***training-input/0.3.0/netcdf'\n",
    "FILTER_FILE: str = \"eccc\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84115ba-7998-4d14-a8e8-0ab81966b736",
   "metadata": {},
   "source": [
    "## Imports packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b8e243-3640-41cd-9933-f4fe50ae7cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.array as da\n",
    "import dask_jobqueue\n",
    "import dask_jobqueue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489fb85a-bac1-4585-bc7e-abd4ff109b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import xarray as xr\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ea4413-dcc5-41ac-b1bd-f4f655ae209e",
   "metadata": {},
   "source": [
    "## Boot Dask Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54010fa6-8b84-4863-bafe-d2557930499e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if BOOT_DASK_CLUSTER:\n",
    "    cluster = dask_jobqueue.SLURMCluster(\n",
    "        cores=12,\n",
    "        processes=6,\n",
    "        memory='128G',\n",
    "        env_extra=['source ***HOME***.bash_profile','conda activate s2s'],\n",
    "        name='agri-dask',\n",
    "        local_directory='***CACHE***', # METTRE VOTRE LOGIN CRIM ICI\n",
    "        walltime='3:00:00'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e6da40-2727-45ef-8ec5-3a79b9042d60",
   "metadata": {},
   "source": [
    "# Extract informations from Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c845c4-4c55-46a5-816e-fed89055c461",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = pathlib.Path(INPUT_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d86294-0cdd-4069-abd8-37a7a2fc3f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eccc_files = sorted([x for x in input_path.iterdir() if x.stem.startswith(FILTER_FILE)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9003ccd2-7e8d-4b01-8769-a6be9bd5b8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables: set = set([os.path.splitext(os.path.basename(str(file)))[0].split(\"-\")[-2] for file in eccc_files])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849c90b0-a178-40fc-8cc7-10433ea1c1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "eccc_files_df: pd.DataFrame = pd.DataFrame(columns=[\"File\", \"Variable_shortname\", \"Variable_longname\", \"Variable_cfname\", \"Unit\", \"Step_type\", \"Level_type\", \"Level\", \"Number_of_points\", \"Missing_values\", \"Dimensions\"])\n",
    "\n",
    "for file, i in zip(eccc_files, tqdm(range(0, len(eccc_files)), desc =\"Extract informations from dataset files\")):\n",
    "    ds = xr.open_dataset(file)\n",
    "    var_name = list(ds.data_vars.keys())\n",
    "    filename = os.path.splitext(os.path.basename(str(file)))[0]\n",
    "    var_shortname = ds[var_name[0]].GRIB_shortName\n",
    "    long_name = ds[var_name[0]].long_name\n",
    "    var_unit = ds[var_name[0]].GRIB_units  \n",
    "    var_cfname = ds[var_name[0]].GRIB_cfVarName\n",
    "    missing_values = ds[var_name[0]].GRIB_missingValue \n",
    "    level = ds[var_name[0]].realization.data\n",
    "    level_type = ds[var_name[0]].GRIB_typeOfLevel\n",
    "    number_of_points = ds[var_name[0]].GRIB_numberOfPoints\n",
    "    step_type = ds[var_name[0]].GRIB_stepType \n",
    "    dim = set([\"forecast_time\", \"latitude\", \"lead_time\", \"longitude\", \"realization\", \"valid_time\"]).symmetric_difference(set(list(ds[var_name[0]].coords.keys())))\n",
    "    \n",
    "    eccc_files_df = eccc_files_df.append({\"File\": filename, \n",
    "                                          \"Variable_shortname\": var_shortname,  \n",
    "                                          \"Variable_longname\": long_name, \n",
    "                                          \"Variable_cfname\": var_cfname, \n",
    "                                          \"Unit\": var_unit,\n",
    "                                          \"Step_type\": step_type,\n",
    "                                          \"Level_type\": level_type,\n",
    "                                          \"Level\": level,\n",
    "                                          \"Number_of_points\": number_of_points,\n",
    "                                          \"Missing_values\": missing_values,\n",
    "                                          \"Dimensions\": dim}, \n",
    "                                         ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afc4db8-11d6-4448-9580-12144d4977d1",
   "metadata": {},
   "source": [
    "## Check available variables with some informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a79ecc5-67a4-458f-aeb8-5b60b1eab105",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_eccc_files_df = eccc_files_df.drop_duplicates(subset=['Variable_shortname'])\n",
    "sub_eccc_files_df.set_index(\"Variable_shortname\", inplace=True)\n",
    "sub_eccc_files_df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0051c4c7-bbaf-4dd7-99b9-01c815ea5565",
   "metadata": {},
   "source": [
    "Questions:\n",
    "- Il semble qu'il y ai différents \"Step_type\". Faut-il le prendre en compte dans la normalisation des données ?\n",
    "- Comment traiter la variable \"Level_type\" ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ae95b2-1a73-47a7-a766-c7cfa051382d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(eccc_files[0])\n",
    "ds"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c5ce0279-a105-4f34-bba3-43b1af2cc5a7",
   "metadata": {},
   "source": [
    "Si pas de pressure level dans les variables c'est un champ de surface\n",
    "\n",
    "TODO:\n",
    "Création du jeux de données applati et normalisé\n",
    "Soumettre le modèle au bot de soumission\n",
    "Soumettre le modèle au bot avec 0.33 par threshold pour voir le résultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012dae8c-282f-4e70-b150-614f41bf8c55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c10afe-5f9a-4125-99a5-b96c7cacbc7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786c7a1d-f7ae-4003-958c-7630e361623c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
