{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unbiased ECMWF\n",
    "\n",
    "Here we propose a small model which is a debiased ECMWF forecast according to the data we have.\n",
    "The plan is\n",
    "* Compute the bias between the ECMWF model and the observations\n",
    "* Make a debiased model\n",
    "* Turn this model into a probabilistic forecast\n",
    "* Score the forecast\n",
    "For now we do it only on temperature and weeks 3-4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.array as da\n",
    "import dask.distributed\n",
    "import dask_jobqueue\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import scipy.stats\n",
    "import xarray as xr\n",
    "import xskillscore as xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crims2s.util import fix_dataset_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_TRAIN = '***BASEDIR***training-input/0.3.0/netcdf'\n",
    "OBSERVATIONS = '***BASEDIR***training-output-reference/'\n",
    "BENCHNMARK = '***BASEDIR***training-output-benchmark/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boost dask cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = dask_jobqueue.SLURMCluster(\n",
    "    env_extra=['source ***HOME***.bash_profile','conda activate s2s'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(jobs=2)  # Scale to two working nodes as configured.\n",
    "client = dask.distributed.Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ECMWF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CENTER = 'ecmwf'\n",
    "FIELD = 't2m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = pathlib.Path(INPUT_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files = sorted([f for f in input_path.iterdir() if CENTER in f.stem and FIELD in f.stem])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecmwf = xr.open_mfdataset(input_files, preprocess=fix_dataset_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecmwf_w34 = ecmwf.sel(lead_time=slice('14D', '27D'))\n",
    "ecmwf_w34_train = ecmwf_w34.sel(forecast_year=slice(None, 2018))\n",
    "ecmwf_w34_val = ecmwf_w34.sel(forecast_year=slice(2019, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecmwf_w34_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_path = pathlib.Path(OBSERVATIONS)\n",
    "obs_files = [f for f in obs_path.iterdir() if 't2m' in f.stem]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = xr.open_mfdataset(obs_files, preprocess=fix_dataset_dims).isel(lead_time=slice(1, None))\n",
    "obs_w34 = obs.sel(lead_time=slice('14D', '27D'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_w34_train = obs_w34.sel(forecast_year=slice(None, 2018))\n",
    "obs_w34_val = obs_w34.sel(forecast_year=slice(2019, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_w34_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debiasing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute bias using training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecmwf_w34_bias = (obs_w34_train - ecmwf_w34_train).mean(dim=['lead_time', 'forecast_year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecmwf_w34_bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias correct ECMWF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecmwf_w34_val_corrected = ecmwf_w34_val + ecmwf_w34_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecmwf_w34_val_corrected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turn into probabilistic forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get thresholds from train observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_w34_train_thresholds = obs_w34_train.quantile([0.33, 0.67], dim=['lead_time', 'forecast_year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_w34_train_thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute p of thresholds according to the model\n",
    "\n",
    "There are two ways to do this. \n",
    "We can either count the amount of members that are whithin each category.\n",
    "Or compute a distribution of all the members of the model, and then compute the value of the CDF for each threshold.\n",
    "\n",
    "Here we do it using the distribution method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute a distribution of the members of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecmwf_w34_val_corrected_mean = ecmwf_w34_val_corrected.mean(dim=['realization', 'lead_time'])\n",
    "ecmwf_w34_val_corrected_std = ecmwf_w34_val_corrected.std(dim=['realization', 'lead_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the value of the CDF for each threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecmwf_w34_val_corrected_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_probabilistic(forecast, obs):\n",
    "    thresholds = obs.quantile([0.33, 0.67], dim=['lead_time', 'forecast_year'])\n",
    "    \n",
    "    loc = forecast.mean(dim=['realization', 'lead_time']).compute().t2m\n",
    "    scale = forecast.std(dim=['realization', 'lead_time']).compute().t2m\n",
    "    \n",
    "    cdfs = xr.apply_ufunc(scipy.stats.norm.cdf, thresholds.t2m, dask='allowed', kwargs={'loc': loc, 'scale': scale})\n",
    "    \n",
    "    below = cdfs.isel(quantile=0).drop_vars('quantile')\n",
    "    normal = (cdfs.isel(quantile=1) - cdfs.isel(quantile=0))\n",
    "    above = xr.ones_like(normal) - cdfs.isel(quantile=1).drop_vars('quantile')\n",
    "    \n",
    "    return xr.concat([below, normal, above], 'category').assign_coords(category=['below normal', 'near normal', 'above normal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_probabilistic_forecast = make_probabilistic(ecmwf_w34_val_corrected, obs_w34_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_probabilistic_forecast.isel(category=2, forecast_dayofyear=40).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_probabilistic_forecast.isel(category=1, forecast_dayofyear=40).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = ecmwf_w34_val_corrected_mean.compute().t2m\n",
    "scale = ecmwf_w34_val_corrected_std.compute().t2m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdfs = xr.apply_ufunc(scipy.stats.norm.cdf, obs_w34_train_thresholds.t2m, dask='allowed', kwargs={'loc': loc, 'scale': scale})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdfs.isel(quantile=1).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "below = cdfs.isel(quantile=0).drop_vars('quantile')\n",
    "normal = (cdfs.isel(quantile=1) - cdfs.isel(quantile=0))\n",
    "above = xr.ones_like(normal) - cdfs.isel(quantile=1).drop_vars('quantile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_probabilistic_forecast = xr.concat([below, normal, above], 'category', coords='minimal').assign_coords(category=['below normal', 'near normal', 'above normal'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_probabilistic_forecast.sum(dim='category').isel(forecast_dayofyear=0).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a probabilistic version of the val obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_w34_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = obs_w34_val.mean(dim=['lead_time']).compute().t2m\n",
    "scale = obs_w34_val.std(dim=['lead_time']).compute().t2m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdfs = xr.apply_ufunc(scipy.stats.norm.cdf, obs_w34_train_thresholds.t2m, dask='allowed', kwargs={'loc': loc, 'scale': scale})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "below = cdfs.isel(quantile=0).drop_vars('quantile')\n",
    "normal = (cdfs.isel(quantile=1) - cdfs.isel(quantile=0))\n",
    "above = xr.ones_like(normal) - cdfs.isel(quantile=1).drop_vars('quantile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_probabilistic_obs = xr.concat([below, normal, above], 'category').assign_coords(category=['below normal', 'near normal', 'above normal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_probabilistic_obs.isel(category=2, forecast_dayofyear=0).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare both proba using rps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_probabilistic_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs.rps(val_probabilistic_obs, val_probabilistic_forecast, category_edges=None, input_distributions='p', dim=['forecast_dayofyear']).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_probabilistic_obs.isel(forecast_dayofyear=0, category=2).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_probabilistic_forecast.isel(forecast_dayofyear=0, category=2).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "S2S Challenge",
   "language": "python",
   "name": "s2s"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
